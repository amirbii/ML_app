import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from PIL import Image
import os
import subprocess
from zipfile import ZipFile
import plotly.graph_objects as go
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, consensus_score, confusion_matrix
from sklearn.neighbors import LocalOutlierFactor

api_k = {"username": "amirbi",
         "key": "cce234fe761dad172e451eb0141f1143"}

# def apply_inline_styles():
# css = """
# * {
#  direction: rtl;
#     .st-emotion-cache-13ln4jf{
# max-width: 100% !important;.
# }
# }"""

# st.markdown(f'<style>{css}</style>', unsafe_allow_html=True)


# apply_inline_styles()
####################
st.title("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª ğŸ“")

method = st.radio("Ø±ÙˆØ´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ:", ["ğŸ“¤ CSV", "ğŸŒGithub", "ğŸŒkaggle"])

df = None

if method == "ğŸ“¤ CSV":
    uploaded_file = st.file_uploader("ÙØ§ÛŒÙ„ CSV Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["csv"])
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.success("âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")

elif method == "ğŸŒGithub":
    url = st.text_input("link")
    if st.button("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ"):
        try:
            df = pd.read_csv(url)
            st.success("âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {e}")
elif method == "ğŸŒkaggle":
    url = st.text_input("link")
    if st.button("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ"):
        try:
            os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()

            parts = url.strip("/").split("/")
            slug = f"{parts[-2]}/{parts[-1]}"
            zip_name = f"{parts[-1]}.zip"

            subprocess.run(["kaggle", "datasets", "download", "-d", slug], check=True)

            with ZipFile(zip_name, 'r') as zip_ref:
                zip_ref.extractall("kaggle_data")

            for file in os.listdir("kaggle_data"):
                if file.endswith(".csv"):
                    df = pd.read_csv(os.path.join("kaggle_data", file))
                    st.success("âœ… ÙØ§ÛŒÙ„ CSV Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                    break
            else:
                st.warning("âš ï¸ ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² Kaggle: {e}")

####################
if df is not None:
    st.subheader("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯ÛŒØªØ§ ğŸ“Š")

    st.write(f"ğŸ”¢ Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡: {df.shape[0]} Ù†Ù…ÙˆÙ†Ù‡ Ã— {df.shape[1]} Ø³ØªÙˆÙ†")

    st.write("Data Types")
    st.write(df.dtypes)

    st.write("Missing Values")
    st.write(df.isnull().sum())

    st.write("Descriptive Statistics:")
    st.write(df.describe(include='all'))

    ####################
    st.subheader("Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª ğŸ§¹")

    out = st.radio(" Ø±ÙˆØ´ Ù‡Ø§ÛŒ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡", ["None", "STD + Mean", "IQR", "LOF"])
    button = st.button("ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø­Ø°Ù")

    num = df.select_dtypes(include=np.number).columns
    lenn = len(df)
    df_out = df.copy()
    x = df_out[num]

    if out == "None":
        st.session_state.df_out = df
        st.info("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø­Ø°Ù Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")

    if out != "None" and button:
        if out == "STD + Mean":
            std = 1.5
            mean = x.mean()
            std_val = x.std()

            upper_bound = mean + std * std_val
            lower_bound = mean - std * std_val

            outlier_mask = ((x > upper_bound) | (x < lower_bound))
            valid_mask = ~outlier_mask.any(axis=1)
            df_out = df_out[valid_mask]

        elif out == "IQR":
            Q1 = x.quantile(0.25)
            Q3 = x.quantile(0.75)
            IQR = Q3 - Q1
            mask = ~((x < (Q1 - 1.5 * IQR)) | (x > (Q3 + 1.5 * IQR))).any(axis=1)
            df_out = df_out[mask]

        elif out == "LOF":

            lof = LocalOutlierFactor(n_neighbors=3)
            outlier_pred = lof.fit_predict(x)
            outlier_index = np.where(outlier_pred == -1)
            df_out = df_out.drop(index=outlier_index[0])

        removed = lenn - len(df_out)
        percent = removed / lenn * 100
        st.success(f" Ù†Ù…ÙˆÙ†Ù‡ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯: {removed}")
        st.markdown(f"**ğŸ¯ Ø¯Ø±ØµØ¯ Ù†Ù…ÙˆÙ†Ù‡ Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡:** {percent:.2f}")
        st.session_state.df_out = df_out

if "df_out" in st.session_state:
    st.subheader("Ø¯ÛŒØªØ§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ ğŸ“‰")
    st.write(f"Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡: {df_out.shape[0]} Ù†Ù…ÙˆÙ†Ù‡ Ã— {df_out.shape[1]} Ø³ØªÙˆÙ†")
    st.write(df_out.describe())

####################
st.header("Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ ğŸ§¹")
scale_method = st.radio("Ø±ÙˆØ´ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", ("None", "StandardScaler", "MinMaxScaler"))
button1 = st.button(" Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ")

if button1 and scale_method != "None":
    if 'df_out' in st.session_state:
        df_out = st.session_state.df_out
    else:
        df_out = df

    numeric_cols = df_out.select_dtypes(include=np.number).columns

    if scale_method == "StandardScaler":
        scaler = StandardScaler()
    elif scale_method == "MinMaxScaler":
        scaler = MinMaxScaler()

    scaled_array = scaler.fit_transform(df_out[numeric_cols])
    df_scaled = pd.DataFrame(scaled_array, columns=numeric_cols)

    st.subheader("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡:")
    st.dataframe(df_scaled.head())

elif button1 and scale_method == "None":
    st.info("Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
####################
st.header("ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ â—")

test_size = st.slider("Ù…Ù‚Ø¯Ø§Ø± ØªØ³Øª", min_value=0.0, max_value=0.5, step=0.05, value=0.2)

col1, col2 = st.columns(2)
with col1:
    shuffle = st.checkbox("ğŸ”€ Shuffle", value=True)
with col2:
    stratify = st.checkbox("ğŸ¯ Stratify", value=False)

# Ø§Ù†ØªØ®Ø§Ø¨ Ø¯ÛŒØªØ§
if 'df_scaled' in st.session_state:
    df_final = st.session_state.df_scaled
elif 'df_out' in st.session_state:
    df_final = st.session_state.df_out
elif 'df' in locals() and df is not None:
    df_final = df
else:
    df_final = None

target_column = None
button2 = False

if df_final is not None and len(df_final) > 1:
    st.subheader("ğŸ¯ Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ† Ù‡Ø¯Ù:")
    target_column = st.selectbox("Ø³ØªÙˆÙ† Ù„ÛŒØ¨Ù„ (y):", df_final.columns)
    button2 = st.button("Train/Test Split")

if button2 and target_column is not None:
    X = df_final.drop(columns=[target_column])
    y = df_final[target_column]

    st.write("ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø± Ù‡Ø± Ú©Ù„Ø§Ø³:")
    st.write(y.value_counts())

    if stratify and y.value_counts().min() < 2:
        st.error("âŒ Ø¨Ø±Ø§ÛŒ StratifyØŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ Û² Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")
    else:
        stratify_value = y if stratify else None

        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=test_size,
            shuffle=shuffle,
            stratify=stratify_value,
            random_state=42
        )

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± session
        st.session_state.X_train = X_train
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_test = y_test

        st.success("âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù†Ø¯.")
        st.write(f"ğŸŸ© Ø¢Ù…ÙˆØ²Ø´: {X_train.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
        st.write(f"ğŸŸ¥ ØªØ³Øª: {X_test.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")


####################
st.title("Ø§Ù†ÙˆØ§Ø¹ Ù…Ø¯Ù„ ğŸ¤–")

model = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„", ["Logistic", "SVM", "KNN", "Decision Tree"])

st.markdown("### Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ âš™ï¸")

if model == "Logistic":
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        penalty = st.selectbox("Penalty", ["l2", "none"])
    with col2:
        solver = st.selectbox("Solver", ["lbfgs", "liblinear", "saga"])
    with col3:
        C = st.number_input("C", 0.01, 10.0, value=1.0, step=0.1)
    with col4:
        max_iter = st.slider("Max Iterations", 100, 1000, 200, step=50)


elif model == "SVM":
    col1, col2, col3 = st.columns(3)
    with col1:
        c = st.number_input("C", min_value=0.01, max_value=100.0, value=1.0, step=0.1)
    with col2:
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
    with col3:
        gamma = st.selectbox("Gamma", ["auto", "scale"])


elif model == "KNN":
    col1, col2, col3 = st.columns(3)
    with col1:
        k = st.slider("K", min_value=1, max_value=50, value=5)
    with col2:
        weight = st.selectbox("Weight", ["uniform", "distance"])
    with col3:
        metric = st.selectbox("Metric", ["euclidean", "manhattan", "minkowski"])


elif model == "Decision Tree":
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        criterion = st.selectbox("Criterion", ["gini", "entropy"])
    with col2:
        max_depth = st.number_input("Max Depth", min_value=1, max_value=50, value=5)
    with col3:
        min_samples_leaf = st.number_input("min_samples_leaf", min_value=1, max_value=100, value=1)
    with col4:
        min_samples_split = st.number_input("min_samples_split", min_value=2, max_value=20, value=2)
####################
if st.button("Auto Tuning"):
    st.write("Grid Search")

####################
if st.button("Train"):
    if not all(k in st.session_state for k in ["X_train", "X_test", "y_train", "y_test"]):
        st.warning("âš ï¸ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Train/Test Split ØªÙ‚Ø³ÛŒÙ… Ú©Ù†ÛŒØ¯.")
    else:
        X_train = st.session_state.X_train
        y_train = st.session_state.y_train
        X_test = st.session_state.X_test
        y_test = st.session_state.y_test

        if model == "Logistic":
            clf = LogisticRegression(penalty=penalty, solver=solver, C=C, max_iter=max_iter)
        elif model == "SVM":
            clf = SVC(C=c, kernel=kernel, gamma=gamma)
        elif model == "KNN":
            clf = KNeighborsClassifier(n_neighbors=k, weights=weight, metric=metric)
        elif model == "Decision Tree":
            clf = DecisionTreeClassifier(
                criterion=criterion,
                max_depth=max_depth,
                min_samples_leaf=min_samples_leaf,
                min_samples_split=min_samples_split
            )

        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        acc = accuracy_score(y_test, y_pred)
        st.success("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯")
        st.markdown(f"**ğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„:** {acc * 100:.2f}")


        st.subheader("ğŸ“Š Confusion Matrix")
        st.write(confusion_matrix(y_test, y_pred))

        st.subheader("ğŸ“‹ Classification Report")
        st.text(classification_report(y_test, y_pred))

    ####################

####################
x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
y = [1, 3, 4, 5, 6]
fig = go.Figure(data=go.Scatter(x=x, y=y))
st.plotly_chart(fig)
####################
st.title("Ø§Ù†ÙˆØ§Ø¹ Ù…Ø¯Ù„ Ø¨ÙˆØ³Øª ğŸ¤–")
####################
st.header("ØªØ³Øª Ù…Ø¯Ù„ ğŸ–¼ï¸")
image_file = st.file_uploader("ÙØ§ÛŒÙ„ ØªØ³Øª Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type=["jpg", "jpeg", "png"])

####################
st.header("ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ù†Ù‡Ø§ÛŒÛŒ ğŸ§¾")
if st.button("Generat Code"):
    pass
#####################
